{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b69ef9d",
   "metadata": {},
   "source": [
    "# Causal ABA Test Run\n",
    "\n",
    "The goal of this notebook is to achive an end-to-end run of the causal-aba framework for any dataset.\n",
    "This is just an initial exploration of the existing implementations of ABA and their application on the causal discovery problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../ArgCausalDisco')\n",
    "sys.path.insert(0, '../notears')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from ArgCausalDisco.cd_algorithms.models import run_method\n",
    "from ArgCausalDisco.utils.graph_utils import DAGMetrics, dag2cpdag\n",
    "from ArgCausalDisco.utils.helpers import random_stability, logger_setup\n",
    "from ArgCausalDisco.utils.data_utils import load_bnlearn_data_dag, simulate_dag\n",
    "import warnings\n",
    "import cdt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cdt.SETTINGS.rpath = '/usr/local/bin/Rscript'\n",
    "Path('./results').mkdir(exist_ok=True)\n",
    "\n",
    "version = 'bnlearn_50rep'\n",
    "log_path = f'results/log_{version}.log'\n",
    "logger_setup(log_path)\n",
    "data_path='../ArgCausalDisco/datasets'\n",
    "sample_size = 5000\n",
    "n_runs = 1\n",
    "device = 0\n",
    "load_res = False\n",
    "save_res = False\n",
    "dataset_list = [\n",
    "                'cancer', \n",
    "                # 'earthquake', \n",
    "                # 'survey', \n",
    "                # 'asia'\n",
    "                ]\n",
    "model_list = [\n",
    "            'random'\n",
    "            ,'mpc'\n",
    "            ,'abapc'\n",
    "            # ,'fgs'   javabridge doesn't work with python, so bd2kccd/py-causal won't work\n",
    "            ,'nt'\n",
    "            ]\n",
    "\n",
    "if load_res:         \n",
    "    mt_res = pd.DataFrame(np.load(f\"results/stored_results_{version}.npy\", allow_pickle=True), \n",
    "                       columns = ['dataset', 'model', 'elapsed_mean', 'elapsed_std', 'nnz_mean', 'nnz_std', \n",
    "                                'fdr_mean', 'fdr_std', 'tpr_mean', 'tpr_std', 'fpr_mean', 'fpr_std', \n",
    "                                'precision_mean', 'precision_std', 'recall_mean', 'recall_std',\n",
    "                                'F1_mean', 'F1_std', 'shd_mean', 'shd_std','sid_mean', 'sid_std'])\n",
    "    mt_res_cpdag = pd.DataFrame(np.load(f\"results/stored_results_{version}_cpdag.npy\", allow_pickle=True), \n",
    "                       columns = ['dataset', 'model', 'elapsed_mean', 'elapsed_std', 'nnz_mean', 'nnz_std', \n",
    "                                'fdr_mean', 'fdr_std', 'tpr_mean', 'tpr_std', 'fpr_mean', 'fpr_std', \n",
    "                                'precision_mean', 'precision_std', 'recall_mean', 'recall_std',\n",
    "                                'F1_mean', 'F1_std', 'shd_mean', 'shd_std', 'sid_low_mean', 'sid_low_std', 'sid_high_mean', 'sid_high_std'])\n",
    "    ## save backup to npy\n",
    "    np.save(f\"results/stored_results_{version}_bkp.npy\", mt_res )\n",
    "    np.save(f\"results/stored_results_{version}_cpdag_bkp.npy\", mt_res_cpdag )\n",
    "else:\n",
    "    mt_res = pd.DataFrame()\n",
    "    mt_res_cpdag = pd.DataFrame()\n",
    "\n",
    "for dataset_name in dataset_list:\n",
    "    names_dict = {'pc':'PC', 'pc_max':'Max-PC', 'fgs':'FGS', 'spc':'Shapley-PC', 'mpc':'MPC', 'cpc':'CPC', 'abapc':'ABAPC (Ours)', 'cam':'CAM', 'nt':'NOTEARS-MLP', 'mcsl':'MCSL-MLP', 'ges':'GES', 'random':'Random'}\n",
    "    # B_true = nx.adjacency_matrix(true_causal_matrix).todense()\n",
    "\n",
    "    for method in model_list:\n",
    "        random_stability(2024)\n",
    "        seeds_list = np.random.randint(0, 10000, (n_runs, )).tolist()\n",
    "        # seeds_list = [seeds_list[0]] if method in ['abapc', 'spc', 'pc_max', 'cam', 'fgs', 'pc', 'mpc', 'cpc'] else seeds_list\n",
    "        logging.debug(f'Seeds:{seeds_list}')\n",
    "        logging.info(f\"Running {method}\")\n",
    "        \n",
    "        method_res = []\n",
    "        method_res_cpdag = []\n",
    "        for seed in seeds_list:\n",
    "            ##Load data\n",
    "            X_s, B_true = load_bnlearn_data_dag(dataset_name, data_path, sample_size, seed=seed, print_info=True if seed == seeds_list[0] else False, standardise=True)\n",
    "            if method=='random':\n",
    "                random_stability(seed)\n",
    "                start = datetime.now()\n",
    "                B_est = simulate_dag(d=B_true.shape[1], s0=B_true.sum().astype(int), graph_type='ER')\n",
    "                elapsed = (datetime.now()-start).total_seconds()\n",
    "                mt_cpdag = DAGMetrics(dag2cpdag(B_est), B_true).metrics\n",
    "                mt_dag = DAGMetrics(B_est, B_true).metrics\n",
    "            else:\n",
    "                W_est, elapsed = run_method(X_s, method, seed, test_alpha=0.01, test_name='fisherz', device=device, scenario=f\"{method}_{version}_{dataset_name}\")\n",
    "                if 'Tensor' in str(type(W_est)):\n",
    "                    W_est = np.asarray([list(i) for i in W_est])\n",
    "                logger_setup(f'results/log_{version}.log', continue_logging=True)\n",
    "                if W_est is None:\n",
    "                    mt_cpdag = {'nnz':np.nan, 'fdr':np.nan, 'tpr':np.nan, 'fpr':np.nan, 'precision':np.nan, 'recall':np.nan, 'F1':np.nan, 'shd':np.nan, 'sid':np.nan}\n",
    "                    mt_dag = {'nnz':np.nan, 'fdr':np.nan, 'tpr':np.nan, 'fpr':np.nan, 'precision':np.nan, 'recall':np.nan, 'F1':np.nan, 'shd':np.nan, 'sid':np.nan}\n",
    "                else:\n",
    "                    B_est = (W_est != 0).astype(int)\n",
    "                    mt_cpdag = DAGMetrics(dag2cpdag(B_est), B_true).metrics\n",
    "                    B_est = (W_est > 0).astype(int)\n",
    "                    mt_dag = DAGMetrics(B_est, B_true).metrics\n",
    "            # calculate metrics\n",
    "            logging.info({'dataset':dataset_name, 'model':names_dict[method], 'elapsed':elapsed , **mt_dag})\n",
    "            logging.info({'dataset':dataset_name, 'model':names_dict[method], 'elapsed':elapsed , **mt_cpdag})\n",
    "            \n",
    "            method_res.append({'dataset':dataset_name, 'model':names_dict[method], 'elapsed':elapsed , **mt_dag})\n",
    "            if type(mt_cpdag['sid'])==tuple:\n",
    "                mt_sid_low = mt_cpdag['sid'][0]\n",
    "                mt_sid_high = mt_cpdag['sid'][1]\n",
    "            else:\n",
    "                mt_sid_low = mt_cpdag['sid']\n",
    "                mt_sid_high = mt_cpdag['sid']\n",
    "            mt_cpdag.pop('sid')\n",
    "            mt_cpdag['sid_low'] = mt_sid_low\n",
    "            mt_cpdag['sid_high'] = mt_sid_high\n",
    "            method_res_cpdag.append({'dataset':dataset_name, 'model':names_dict[method], 'elapsed':elapsed , **mt_cpdag})\n",
    "            \n",
    "        method_sum = pd.DataFrame(method_res).groupby(['dataset','model'], as_index=False).agg(['mean','std']).round(2).reset_index(drop=True)\n",
    "        method_sum.columns = method_sum.columns.map('_'.join).str.strip('_')\n",
    "        mt_res = pd.concat([mt_res, method_sum], sort=False)\n",
    "\n",
    "        method_sum = pd.DataFrame(method_res_cpdag).groupby(['dataset','model'], as_index=False).agg(['mean','std']).round(2).reset_index(drop=True)\n",
    "        method_sum.columns = method_sum.columns.map('_'.join).str.strip('_')\n",
    "        mt_res_cpdag = pd.concat([mt_res_cpdag, method_sum], sort=False)\n",
    "\n",
    "        if save_res:\n",
    "            np.save(f\"results/stored_results_{version}.npy\", mt_res )\n",
    "            np.save(f\"results/stored_results_{version}_cpdag.npy\", mt_res_cpdag )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ce328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aba-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
