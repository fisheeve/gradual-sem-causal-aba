{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33259764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351864d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87461d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graphs_compare = pd.read_csv('../../results_pure_aba/compare_semantics_random.csv')\n",
    "random_graphs_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnlearn_compare = pd.read_csv('../../results_pure_aba/compare_semantics_bnlearn.csv')\n",
    "bnlearn_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graphs_compare.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnlearn_compare.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b189d0b",
   "metadata": {},
   "source": [
    "# Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_runtimes = pd.read_csv('../../results_pure_aba/compare_abapc_random.csv')\n",
    "old_runtimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_runtimes_grouped = old_runtimes.groupby(['n_nodes', 'n_edges'], as_index=False).agg(\n",
    "    pure_abapc_mean=('pure_abapc_elapsed', 'mean'),\n",
    "    pure_abapc_std=('pure_abapc_elapsed', 'std'),\n",
    "    old_mean=('old_elapsed', 'mean'),\n",
    "    old_std=('old_elapsed', 'std')\n",
    ")\n",
    "old_runtimes_grouped = old_runtimes_grouped[old_runtimes_grouped['n_nodes'] <= 6].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844df9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = random_graphs_compare.groupby(['n_nodes', 'n_edges'], as_index=False).agg(\n",
    "    ST_elapsed_mean=('ST_elapsed', 'mean'),\n",
    "    ST_elapsed_std=('ST_elapsed', 'std'),\n",
    "    CO_elapsed_mean=('CO_elapsed', 'mean'),\n",
    "    CO_elapsed_std=('CO_elapsed', 'std'),\n",
    "    PR_elapsed_mean=('PR_elapsed', 'mean'),\n",
    "    PR_elapsed_std=('PR_elapsed', 'std'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29394d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_runtime_custom(df, df2, plot_width=750, plot_height=300, font_size=20, save_figs=False, output_name=\"random_graphs_runtime.html\"):\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1, shared_yaxes=True)\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    semantics = ['ST', 'CO', 'PR']\n",
    "    for color, sem in zip(colors, semantics):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['n_nodes'].astype(str),\n",
    "                y=df[f'{sem}_elapsed_mean'],\n",
    "                error_y=dict(type='data', array=df[f'{sem}_elapsed_std'], thickness=2),\n",
    "                mode='lines+markers',\n",
    "                name=sem,\n",
    "                line=dict(color=color, width=2),\n",
    "                marker=dict(symbol='circle', size=8, color=color),\n",
    "                opacity=0.8,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # fig.add_trace(\n",
    "    #     go.Scatter(\n",
    "    #         x=df2['n_nodes'].astype(str),\n",
    "    #         y=df2['pure_abapc_mean'],\n",
    "    #         error_y=dict(type='data', array=df2['pure_abapc_std'], thickness=2),\n",
    "    #         mode='lines+markers',\n",
    "    #         name='new implementation',\n",
    "    #         line=dict(color='black', width=2),\n",
    "    #         marker=dict(symbol='circle', size=8, color='black'),\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    # Method 2: old\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df2['n_nodes'].astype(str),\n",
    "            y=df2['old_mean'],\n",
    "            error_y=dict(type='data', array=df2['old_std'], thickness=2),\n",
    "            mode='lines+markers',\n",
    "            name='existing implementation',\n",
    "            line=dict(color='orange', width=2),\n",
    "            marker=dict(symbol='square', size=8, color='orange'),\n",
    "            opacity=0.8,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Log scale for y-axis\n",
    "    fig.update_yaxes(type=\"log\", title='log(elapsed time [s])')\n",
    "\n",
    "    # X axis title\n",
    "    fig.update_xaxes(title='Number of Nodes (|V|)')\n",
    "\n",
    "    # Layout and style\n",
    "    fig.update_layout(\n",
    "        legend=dict(orientation=\"h\", xanchor=\"center\", x=0.5, yanchor=\"bottom\", y=1.05),\n",
    "        template='plotly_white',\n",
    "        width=plot_width,\n",
    "        height=plot_height,\n",
    "        margin=dict(l=10, r=10, b=80, t=10),\n",
    "        font=dict(size=font_size, family=\"Serif\", color=\"black\")\n",
    "    )\n",
    "\n",
    "    if save_figs:\n",
    "        fig.write_html(output_name)\n",
    "        fig.write_image(output_name.replace('.html', '.jpeg'))\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runtime_custom(runtime_df, old_runtimes_grouped, save_figs=True, output_name='runtime_random_graphs.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca603ac",
   "metadata": {},
   "source": [
    "The preffered' semantics resulted in the least runtime for 6 nodes. \n",
    "\n",
    "While it still has greater slope than the existing implementation, it is still a considerable improvement on the stable semantics runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887adc4a",
   "metadata": {},
   "source": [
    "# SID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_sid_from_json(string_to_read, sid_type='low'):\n",
    "    metrics = json.loads(string_to_read)\n",
    "    sid = metrics['sid']\n",
    "    if isinstance(sid, list):\n",
    "        sid_low, sid_high = sid\n",
    "    elif isinstance(sid, float):\n",
    "        sid_low = sid\n",
    "        sid_high = sid\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected format for SID in JSON string.\")\n",
    "    \n",
    "    if sid_type == 'low':\n",
    "        return sid_low\n",
    "    elif sid_type == 'high':\n",
    "        return sid_high\n",
    "\n",
    "\n",
    "sem_dfs = []\n",
    "for sem in ['ST', 'CO', 'PR']:\n",
    "    sem_df = bnlearn_compare[[f'{sem}_mt_cpdag', 'dataset_name', 'seed']].copy().rename(columns={'dataset_name': 'dataset'})\n",
    "    sem_df['sid_low'] = sem_df[f'{sem}_mt_cpdag'].apply(lambda x: read_sid_from_json(x, 'low'))\n",
    "    sem_df['sid_high'] = sem_df[f'{sem}_mt_cpdag'].apply(lambda x: read_sid_from_json(x, 'high'))\n",
    "    sem_df['model'] = f'ABAPC (New {sem})'\n",
    "    sem_dfs.append(sem_df[['dataset', 'model', 'seed', 'sid_low', 'sid_high']])\n",
    "\n",
    "sem_df_combined = pd.concat(sem_dfs, ignore_index=True)\n",
    "\n",
    "sem_df_combined = sem_df_combined.groupby(['dataset', 'model'], as_index=False).agg(\n",
    "    sid_low_mean=('sid_low', 'mean'),\n",
    "    sid_low_std=('sid_low', 'std'),\n",
    "    sid_high_mean=('sid_high', 'mean'),\n",
    "    sid_high_std=('sid_high', 'std')\n",
    ")\n",
    "sem_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e997ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.insert(0,'../../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "sys.path.append('../../ArgCausalDisco/utils/')\n",
    "from ArgCausalDisco.utils.plotting import *\n",
    "print(sys.path)\n",
    "\n",
    "cyan = '#00BFFF'\n",
    "emerald = '#50C878'\n",
    "\n",
    "\n",
    "save_figs = True\n",
    "debug = False\n",
    "datasets = ['cancer', 'earthquake', 'survey', 'asia']\n",
    "dags_nodes_map = {'asia':8, 'cancer':5, 'earthquake':5, 'sachs':11, 'survey':6, 'alarm':37, 'child':20, 'insurance':27, 'hailfinder':56, 'hepar2':70}\n",
    "dags_arcs_map = {'asia':8, 'cancer':4, 'earthquake':4, 'sachs':17, 'survey':6, 'alarm':46, 'child':25, 'insurance':52, 'hailfinder':66, 'hepar2':123}\n",
    "methods = ['Random', 'FGS', 'NOTEARS-MLP', 'MPC', 'ABAPC (Existing)', 'ABAPC (New ST)', 'ABAPC (New CO)', 'ABAPC (New PR)']\n",
    "names_dict = {'fgs':'FGS', 'nt':'NOTEARS-MLP', 'mpc':'MPC', 'random':'Random', 'abapc':'ABAPC (Existing)', 'ABAPC (New ST)':'ABAPC (New ST)',\n",
    "              'ABAPC (New CO)':'ABAPC (New CO)', 'ABAPC (New PR)':'ABAPC (New PR)'}\n",
    "symbols_dict = {'abapc':'triangle-down-dot','fgs':'triangle-up-dot','nt':'pentagon-dot','mpc':'hexagon2-dot', 'random':'x'}  \n",
    "colors_dict = {'abapc':sec_blue,'fgs':sec_orange,'nt':main_purple,'mpc':main_green,'random':'grey', 'ABAPC (New ST)':'black',\n",
    "               'ABAPC (New CO)':cyan, 'ABAPC (New PR)':emerald}\n",
    "version = 'bnlearn_50rep' ## for 5000 samples\n",
    "# version = 'bnlearn_dag_v5_2000' ## for 2000 samples\n",
    "\n",
    "version_cpdag = version+'_cpdag'\n",
    "all_sum = pd.read_csv(f\"../../results_pure_aba/stored_results_{version}_cpdag.csv\")\n",
    "all_sum['model'][all_sum['model']=='ABAPC (Ours)'] = 'ABAPC (Existing)'\n",
    "all_sum['model'][all_sum['model']=='ABAPC (ASPforABA)'] = 'ABAPC (New)'\n",
    "all_sum = all_sum[['dataset', 'model', 'sid_low_mean', 'sid_low_std', 'sid_high_mean', 'sid_high_std']].copy()\n",
    "all_sum = pd.concat([all_sum, sem_df_combined], ignore_index=True)\n",
    "\n",
    "\n",
    "all_sum['n_edges'] = all_sum['dataset'].map(dags_arcs_map)\n",
    "all_sum['n_nodes'] = all_sum['dataset'].map(dags_nodes_map)\n",
    "for var in ['SID_low','SID_high']:\n",
    "    all_sum['p_'+var+'_mean'] = all_sum[var.lower()+'_mean'].astype(float)/all_sum['n_edges'].astype(int)\n",
    "    all_sum['p_'+var+'_std'] = all_sum[var.lower()+'_std'].astype(float)/all_sum['n_edges'].astype(int)\n",
    "all_sum['dataset'] = [a.upper() for a in all_sum[\"dataset\"].astype(str)]\n",
    "all_sum['dataset'] = all_sum['dataset'] +np.repeat(\"<br> |V|=\",len(all_sum))+ all_sum[\"n_nodes\"].astype(str)+np.repeat(\", |E|=\",len(all_sum))+\\\n",
    "                     all_sum[\"n_edges\"].astype(str)\n",
    "\n",
    "\n",
    "all_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9699f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_bar_chart_plotly(all_sum, ['p_SID_low','p_SID_high'], names_dict, colors_dict, methods, save_figs=save_figs, output_name=\"./Fig.2_SID_cpdag.html\", debug=False, range_y1=[0,6], range_y2=[0,6])#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfba6af9",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97480c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graphs_compare.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf65183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is best stable model always contained in the full set of complete models?\n",
    "\n",
    "all(random_graphs_compare['is_best_st_in_all_co'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentage of cases is the best stable model contained in the full set of complete models?\n",
    "random_graphs_compare['is_best_st_in_all_co'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077690f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is best stable model always contained in the full set of preferred' models?\n",
    "all(random_graphs_compare['is_best_st_in_all_pr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5444a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentage of cases is the best stable model contained in the full set of preferred' models?\n",
    "random_graphs_compare['is_best_st_in_all_pr'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is best preferred' model always contained in the full set of complete models?\n",
    "all(random_graphs_compare['is_best_pr_in_all_co'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ac567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are stable models subset of preferred' models?\n",
    "all(random_graphs_compare['is_all_st_subset_of_all_pr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentafe of cases are the stable models a subset of the preferred' models?\n",
    "random_graphs_compare['is_all_st_subset_of_all_pr'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are stable models subset of complete' models?\n",
    "all(random_graphs_compare['is_all_st_subset_of_all_co'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentafe of cases are the stable models a subset of the complete models?\n",
    "random_graphs_compare['is_all_st_subset_of_all_co'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are preferred' models subset of complete' models?\n",
    "all(random_graphs_compare['is_all_pr_subset_of_all_co'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25684f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cases when best stable model is stronger than best preferred model: \", \n",
    "      random_graphs_compare[random_graphs_compare['ST_best_I'] > random_graphs_compare['PR_best_I']].shape[0] / len(random_graphs_compare) * 100, '%')\n",
    "print(\"cases when best stable model is weaker than best preferred model: \", \n",
    "      random_graphs_compare[random_graphs_compare['ST_best_I'] < random_graphs_compare['PR_best_I']].shape[0] / len(random_graphs_compare) * 100, '%')\n",
    "print(\"cases when best preferred model is equal to the best complete model: \",\n",
    "      random_graphs_compare[random_graphs_compare['CO_best_model']== random_graphs_compare['PR_best_model']].shape[0] / len(random_graphs_compare) * 100, '%')\n",
    "print(\"cases when the strength of the best preferred model is equal to the strength of the best complete model: \",\n",
    "      random_graphs_compare[random_graphs_compare['CO_best_I']== random_graphs_compare['PR_best_I']].shape[0] / len(random_graphs_compare) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62b1c0",
   "metadata": {},
   "source": [
    "Concluding that complete and preferred result in same output.\n",
    "\n",
    "Stable results in better output that preferred only in 10.5% of times according to model strength.\n",
    "Stable results in worse output that preferred only in 20.5% of times according to model strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All facts are considered always, thus in case of preferred or complete the algo runs only once. No fact elimination is performed.\n",
    "all(random_graphs_compare['CO_used_num_facts'] == random_graphs_compare['CO_total_num_facts']), all(random_graphs_compare['PR_used_num_facts'] == random_graphs_compare['PR_total_num_facts']), all(random_graphs_compare['ST_used_num_facts'] == random_graphs_compare['ST_total_num_facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cee231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: all best models are DAGs\n",
    "\n",
    "sys.path.insert(0, '../../ArgCausalDisco')\n",
    "from ArgCausalDisco.utils.graph_utils import is_dag\n",
    "from src.abasp.utils import get_graph_matrix\n",
    "\n",
    "for sem in ['ST', 'CO', 'PR']:\n",
    "    is_dag_list = []\n",
    "    for n_nodes, model in zip(random_graphs_compare['n_nodes'], random_graphs_compare[f'{sem}_best_model']):\n",
    "        model = eval(model)\n",
    "        graph_matrix = get_graph_matrix(n_nodes, model)\n",
    "        is_dag_list.append(is_dag(graph_matrix))\n",
    "    print(f\"Is all {sem} best models a DAGs? {all(is_dag_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0703c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
