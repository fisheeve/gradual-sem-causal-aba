{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29fa0027",
   "metadata": {},
   "source": [
    "# Show discrepancy between experiment results with preferred semantics\n",
    "\n",
    "Consider a 3 node graph and generate a random set of dependency and independency facts. Run original causal ABA and new one with PR' semantics and compare outputs.\n",
    "Investigate the discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eb5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/aba-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:root:You can use `os.environ['CASTLE_BACKEND'] = backend` to set the backend(`pytorch` or `mindspore`).\n",
      "INFO:root:You are using ``pytorch`` as the backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "sys.path.insert(0, '../../ArgCausalDisco/')\n",
    "sys.path.insert(0, '../../notears/')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ArgCausalDisco.utils.helpers import random_stability\n",
    "from ArgCausalDisco.abapc import ABAPC\n",
    "\n",
    "from src.abapc import get_arrow_sets\n",
    "from src.utils.bn_utils import get_dataset\n",
    "\n",
    "from ArgCausalDisco.causalaba import CausalABA\n",
    "from itertools import combinations\n",
    "from src.utils.utils import powerset\n",
    "from src.utils.enums import Fact, RelationEnum\n",
    "import numpy as np\n",
    "from src.utils.utils import get_arrows_from_model\n",
    "from src.causal_aba.factory import ABASPSolverFactory\n",
    "from ArgCausalDisco.utils.graph_utils import initial_strength, set_of_models_to_set_of_graphs\n",
    "\n",
    "from ArgCausalDisco.utils.helpers import random_stability, logger_setup\n",
    "logger_setup(f'./log.log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09f82c",
   "metadata": {},
   "source": [
    "## For Random Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d582c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_facts(n_nodes):\n",
    "    indep_facts = []\n",
    "    dep_facts = []\n",
    "    for X, Y in combinations(range(n_nodes), 2):\n",
    "        for S in powerset(set(range(n_nodes)) - {X, Y}):\n",
    "            dep_facts.append(Fact(relation=RelationEnum.dep,\n",
    "                              node1=X,\n",
    "                              node2=Y,\n",
    "                              node_set=S,\n",
    "                              score=0))  # score placeholder\n",
    "            indep_facts.append(Fact(relation=RelationEnum.indep,\n",
    "                                node1=X,\n",
    "                                node2=Y,\n",
    "                                node_set=S,\n",
    "                                score=0))   \n",
    "    return dep_facts, indep_facts\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3630bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_fact_tuple(fact):\n",
    "    X, Y, S, dep_type_PC, I = fact.node1, fact.node2, fact.node_set, fact.relation.value, fact.score\n",
    "    s_str = 'empty' if len(S)==0 else 's'+'y'.join([str(i) for i in S])\n",
    "    return(X,S,Y,dep_type_PC, f\"{dep_type_PC}({X},{Y},{s_str}).\", I)\n",
    "\n",
    "def get_fact_location(facts, base_location='./facts.lp'):\n",
    "\n",
    "    facts_location = base_location\n",
    "    facts_location_wc = base_location.replace('.lp', '_wc.lp')\n",
    "    facts_location_I = base_location.replace('.lp', '_I.lp')\n",
    "\n",
    "    facts = [generate_fact_tuple(fact) for fact in facts]\n",
    "\n",
    "\n",
    "    ### Save external statements\n",
    "    with open(facts_location, \"w\") as f:\n",
    "        for n, s in enumerate(facts):\n",
    "            f.write(f\"#external ext_{s[4]}\\n\")\n",
    "    ### Save weak constraints\n",
    "    with open(facts_location_wc, \"w\") as f:\n",
    "        for n, s in enumerate(facts):\n",
    "            print(s)\n",
    "            f.write(f\":~ {s[4]} [-{int(s[5]*1000)}]\\n\")\n",
    "    ### Save inner strengths\n",
    "    with open(facts_location_I, \"w\") as f:\n",
    "        for n, s in enumerate(facts):\n",
    "            f.write(f\"{s[4]} I={s[5]}, NA\\n\")\n",
    "        \n",
    "    return facts_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4129831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_facts(n_nodes):\n",
    "    dep_facts, indep_facts = all_possible_facts(n_nodes)\n",
    "\n",
    "    indep_scores = np.random.uniform(0, 1, len(indep_facts))\n",
    "    dep_scores = np.random.uniform(0, 1, len(dep_facts))\n",
    "\n",
    "    for i, fact in enumerate(indep_facts):\n",
    "        fact.score = indep_scores[i]\n",
    "\n",
    "    for i, fact in enumerate(dep_facts):\n",
    "        fact.score = dep_scores[i]\n",
    "    \n",
    "    num_dep = np.random.randint(0, len(dep_facts)//2)\n",
    "    num_indep = np.random.randint(0, len(indep_facts)//2)\n",
    "    indexes = np.random.choice(len(dep_facts), num_dep+num_indep, replace=False)\n",
    "    dep_facts = [dep_facts[i] for i in indexes[:num_dep]]\n",
    "    indep_facts = [indep_facts[i] for i in indexes[num_dep:]]\n",
    "    facts = dep_facts + indep_facts\n",
    "\n",
    "    return facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae1b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_impl_models(facts, n_nodes, semantics='ST'):\n",
    "    sorted_facts = sorted(facts, key=lambda x: x.score, reverse=True)\n",
    "\n",
    "    #  TODO: replace by logging\n",
    "    print(f\"All facts extracted: {sorted_facts}\")\n",
    "\n",
    "    # binary search to find the largest fact set where stable extensions exist\n",
    "\n",
    "    factory = ABASPSolverFactory(n_nodes=n_nodes)\n",
    "    fact_idx = len(sorted_facts)\n",
    "\n",
    "    while fact_idx >= 0:\n",
    "        solver, all_paths = factory._create_solver(sorted_facts[:fact_idx])\n",
    "        models = solver.enumerate_extensions(semantics)\n",
    "        if models is not None and len(models) > 0:\n",
    "            break\n",
    "        fact_idx -= 1\n",
    "    # TODO: replace by logging\n",
    "    print(f\"Number of facts kept: {fact_idx}\")\n",
    "    arrow_sets = [get_arrows_from_model(model) for model in models]\n",
    "    return arrow_sets, models, sorted_facts[:fact_idx], all_paths, solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89354b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(n_nodes, seed, semantics='ST'):\n",
    "    np.random.seed(seed)\n",
    "    all_fact_choices = get_random_facts(n_nodes)\n",
    "    with open('./facts_initial.txt', 'w') as f:\n",
    "        for x in sorted(all_fact_choices, key=lambda x: x.score, reverse=True):\n",
    "            f.write(f\"{x}\\n\")\n",
    "    all_fact_choices = sorted(all_fact_choices, key=lambda x: x.score, reverse=True)\n",
    "    all_fact_choices = all_fact_choices[:4]\n",
    "\n",
    "    \n",
    "    facts_location = get_fact_location(all_fact_choices, base_location='./facts.lp')\n",
    "    model_sets, multiple_solutions = CausalABA(n_nodes, facts_location, weak_constraints=True, skeleton_rules_reduction=True,\n",
    "                                            fact_pct=1.0, search_for_models='first',\n",
    "                                            opt_mode='optN', print_models=False, set_indep_facts=False)\n",
    "    old_models, MEC = set_of_models_to_set_of_graphs(model_sets, n_nodes, False)\n",
    "\n",
    "    new_models, new_models_full, facts, all_paths, solver = get_new_impl_models(all_fact_choices, n_nodes, semantics)\n",
    "    new_models = {frozenset(model) for model in new_models}\n",
    "\n",
    "    print(seed)\n",
    "    print('old: ', old_models)\n",
    "    print('new: ', new_models)\n",
    "\n",
    "    if old_models == new_models:\n",
    "        ans = True\n",
    "    else:\n",
    "        ans = False\n",
    "\n",
    "    return ans, old_models, new_models, new_models_full, facts, all_paths, solver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e66a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMANTICS = 'PR'\n",
    "problem = False\n",
    "N_NODES = 3\n",
    "for seed in range(0, 10):\n",
    "    ans, old_models, new_models, new_models_full, facts, all_paths, solver = compare(N_NODES, seed, SEMANTICS)\n",
    "    if not ans:\n",
    "        print(f\"Discrepancy found for seed {seed}!\")\n",
    "        problem = True\n",
    "        break\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b74bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f967c422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({(1, 2)}), frozenset({(0, 2)})}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_models - old_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fad16511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_models - new_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9206d9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Fact(relation=<RelationEnum.dep: 'dep'>, node1=0, node2=1, node_set=(2,), score=np.float64(0.6192709663506637)),\n",
       " Fact(relation=<RelationEnum.dep: 'dep'>, node1=0, node2=1, node_set=(), score=np.float64(0.2046486340378425))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06196c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 {arr_1_2, blocked_path_0_1__0__, noe_0_1, blocked_path_0_1__0__2} |= {-noe_1_2, dpath_1_2, -indep_0_1__, -arr_2_1, -arr_1_0, -arr_0_1, -indep_0_1__2}\n",
      "8 {arr_0_2, blocked_path_0_1__0__, noe_0_1, blocked_path_0_1__0__2} |= {-arr_2_0, -indep_0_1__, -noe_0_2, -arr_1_0, dpath_0_2, -arr_0_1, -indep_0_1__2}\n"
     ]
    }
   ],
   "source": [
    "arrow_sets = [get_arrows_from_model(model) for model in new_models_full]\n",
    "\n",
    "for m in new_models - old_models:\n",
    "    index = arrow_sets.index(m)\n",
    "    print(index, new_models_full[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1fc9b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): [(0, 1), (0, 2, 1)]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "329d6df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arr_0_1',\n",
       " 'arr_0_2',\n",
       " 'arr_1_0',\n",
       " 'arr_1_2',\n",
       " 'arr_2_0',\n",
       " 'arr_2_1',\n",
       " 'blocked_path_0_1__0__',\n",
       " 'blocked_path_0_1__0__2',\n",
       " 'blocked_path_0_1__1__',\n",
       " 'blocked_path_0_1__1__2',\n",
       " 'indep_0_1__',\n",
       " 'indep_0_1__2',\n",
       " 'noe_0_1',\n",
       " 'noe_0_2',\n",
       " 'noe_1_2'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb99cb",
   "metadata": {},
   "source": [
    "Focusing on the  following extension:  \n",
    "```\n",
    "{arr_1_2, blocked_path_0_1__0__, noe_0_1, blocked_path_0_1__0__2} |= {-noe_1_2, dpath_1_2, -indep_0_1__, -arr_2_1, -arr_1_0, -arr_0_1, -indep_0_1__2} \n",
    "\n",
    "```\n",
    "\n",
    "With facts:\n",
    "\n",
    "```\n",
    "[Fact(relation=<RelationEnum.dep: 'dep'>, node1=0, node2=1, node_set=(2,), score=np.float64(0.6192709663506637)),\n",
    " Fact(relation=<RelationEnum.dep: 'dep'>, node1=0, node2=1, node_set=(), score=np.float64(0.2046486340378425))]\n",
    " ```\n",
    "\n",
    " With paths:\n",
    "\n",
    " ```\n",
    " {(0, 1): [(0, 1), (0, 2, 1)]}\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab60cde",
   "metadata": {},
   "source": [
    "So the facts are that nodes 0 and 1 are dependent when conditioned on node 2, and they are also dependent unconditionally.  \n",
    "\n",
    "However we get a \"preferred\" extension where there is only an arrow from 1 to 2 and that's it. This means that the dependency facts are not satisfied.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971429ee",
   "metadata": {},
   "source": [
    "\n",
    "Q: So why isn't the independency of 0 and 1 included to invalidate this extension due to a conflict?  \n",
    "A: Because it is attacked by empty set, from which it can't be defended.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d3722",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q: Then why aren't  `blocked_path_0_1__1__` or `blocked_path_0_1__1__2` included? They are clearly true given the circumstances. And if these were included then independence would be derived from the extension and wound conflict the dependency fact, and everything would've worked out.  \n",
    "\n",
    "\n",
    "A: They are not included because they are not defended. They are not defended because of the following:\n",
    "\n",
    "Thes blocked paths correspond to the path (0, 2, 1), according to their path id of 1. These blocked path assumptions can be attacked by arrows forming an active collider tree. These arrows in this case are `arr_1_2` and `arr_2_0`. The `blocked_path_0_1__1__` is attacked by {`arr_1_2`, `arr_2_0`}. Both `arr_1_2` and `arr_2_0` are not attacked by the accepted assumption set: `arr_1_2` is included in it and `arr_2_0` is not attacked. So why isn't `arr_2_0` included then? Because it is attacked by `noe_0_2` and is not defended from it. Why isn't `noe_0_2` included? Because it is attacked by `arr_2_0` and is not defended from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1733fd3",
   "metadata": {},
   "source": [
    "We arrived at an example of a COMPLETE extension in Causal ABA framework that is not faithful to the d-separations in the graph. These d-separations are in this case dependence relations encoded as facts in the Causal ABAF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88fef5c",
   "metadata": {},
   "source": [
    "Maybe the maximisation didn't work properly? Let's check that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c180d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subset found\n"
     ]
    }
   ],
   "source": [
    "for model1 in new_models_full:\n",
    "    break_var = False\n",
    "    for model2 in new_models_full:\n",
    "        assums1 = set(model1.assumptions)\n",
    "        assums2 = set(model2.assumptions)\n",
    "        if assums1 != assums2 and (assums1.issubset(assums2) or assums2.issubset(assums1)):\n",
    "            print(\"Subset found:\")\n",
    "            print(\"Model 1:\", assums1)\n",
    "            print(\"Model 2:\", assums2)\n",
    "            break_var = True\n",
    "            break\n",
    "    if break_var:\n",
    "        break\n",
    "else:\n",
    "    print(\"No subset found\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e3e7c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'arr_1_0', 'arr_1_2', 'blocked_path_0_1__1__', 'arr_0_2'}\n",
      "1 {'arr_1_0', 'arr_1_2', 'blocked_path_0_1__1__2', 'arr_2_0'}\n",
      "2 {'arr_2_0', 'arr_0_1', 'blocked_path_0_1__1__2', 'arr_2_1'}\n",
      "3 {'arr_0_1', 'arr_1_2', 'blocked_path_0_1__1__', 'arr_0_2'}\n",
      "4 {'arr_1_2', 'blocked_path_0_1__1__2', 'noe_0_2', 'blocked_path_0_1__1__', 'arr_0_1'}\n",
      "5 {'blocked_path_0_1__1__2', 'arr_2_0', 'blocked_path_0_1__1__', 'arr_0_1', 'noe_1_2'}\n",
      "6 {'arr_1_2', 'blocked_path_0_1__0__', 'noe_0_1', 'blocked_path_0_1__0__2'}\n",
      "7 {'arr_1_0', 'arr_1_2', 'blocked_path_0_1__1__2', 'noe_0_2', 'blocked_path_0_1__1__'}\n",
      "8 {'arr_0_2', 'blocked_path_0_1__0__', 'noe_0_1', 'blocked_path_0_1__0__2'}\n",
      "9 {'arr_1_0', 'blocked_path_0_1__1__2', 'blocked_path_0_1__1__', 'noe_1_2', 'arr_0_2'}\n",
      "10 {'arr_0_1', 'arr_0_2', 'blocked_path_0_1__1__2', 'arr_2_1'}\n",
      "11 {'blocked_path_0_1__1__2', 'blocked_path_0_1__1__', 'noe_1_2', 'arr_0_1', 'arr_0_2'}\n",
      "12 {'arr_1_0', 'blocked_path_0_1__1__2', 'arr_2_0', 'blocked_path_0_1__1__', 'noe_1_2'}\n",
      "13 {'arr_1_0', 'blocked_path_0_1__1__2', 'arr_2_0', 'arr_2_1'}\n",
      "14 {'blocked_path_0_1__1__2', 'noe_0_2', 'blocked_path_0_1__1__', 'noe_1_2', 'arr_0_1'}\n",
      "15 {'blocked_path_0_1__1__2', 'noe_0_2', 'arr_2_1', 'blocked_path_0_1__1__', 'arr_0_1'}\n",
      "16 {'arr_1_0', 'blocked_path_0_1__1__2', 'noe_0_2', 'arr_2_1', 'blocked_path_0_1__1__'}\n",
      "17 {'arr_1_0', 'blocked_path_0_1__1__2', 'noe_0_2', 'blocked_path_0_1__1__', 'noe_1_2'}\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(new_models_full):\n",
    "    print(i, m.assumptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a2af2",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We found a MAXIMALLY COMPLETE (or PREFERRED') extension that is not faithful to the d-separations in the graph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aba-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
